{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.dataset import CustomDataset\n",
    "from src.models.resnet import resnet18, resnet34, resnet50, wide_resnet50_2\n",
    "from src.models.de_resnet import de_resnet18, de_resnet34, de_wide_resnet50_2, de_resnet50\n",
    "from test import evaluation\n",
    "from torch.utils.data import DataLoader,DataLoader2\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch \n",
    "import torchvision.transforms as transforms \n",
    "import yaml \n",
    "from tqdm.auto import tqdm \n",
    "import numpy as np \n",
    "import random \n",
    "from tqdm import tqdm \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def loss_function(a, b):\n",
    "    #mse_loss = torch.nn.MSELoss()\n",
    "    cos_loss = torch.nn.CosineSimilarity()\n",
    "    loss = 0\n",
    "    for item in range(len(a)):\n",
    "        #print(a[item].shape)\n",
    "        #print(b[item].shape)\n",
    "        #loss += 0.1*mse_loss(a[item], b[item])\n",
    "        loss += torch.mean(1-cos_loss(a[item].view(a[item].shape[0],-1),\n",
    "                                      b[item].view(b[item].shape[0],-1)))\n",
    "    return loss\n",
    "\n",
    "def loss_concat(a, b):\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    cos_loss = torch.nn.CosineSimilarity()\n",
    "    loss = 0\n",
    "    a_map = []\n",
    "    b_map = []\n",
    "    size = a[0].shape[-1]\n",
    "    for item in range(len(a)):\n",
    "        #loss += mse_loss(a[item], b[item])\n",
    "        a_map.append(F.interpolate(a[item], size=size, mode='bilinear', align_corners=True))\n",
    "        b_map.append(F.interpolate(b[item], size=size, mode='bilinear', align_corners=True))\n",
    "    a_map = torch.cat(a_map,1)\n",
    "    b_map = torch.cat(b_map,1)\n",
    "    loss += torch.mean(1-cos_loss(a_map,b_map))\n",
    "    return \n",
    "\n",
    "\n",
    "#def run \n",
    "cfg = yaml.load(open('./configs/mvtec.yaml','r'), Loader=yaml.FullLoader)\n",
    "setup_seed(cfg['TRAIN']['seed'])\n",
    "device = 'cuda:0'\n",
    "trainloader = DataLoader(\n",
    "                dataset = CustomDataset(\n",
    "                                        root          = cfg['DATA']['datadir'],\n",
    "                                        img_size      = cfg['DATA']['imgsize'],\n",
    "                                        transform     = transforms.Compose([transforms.ToTensor()]),\n",
    "                                        img_cls       = cfg['DATA']['imgcls'],\n",
    "                                        mode          = cfg['DATA']['mode'],\n",
    "                                        train         = True \n",
    "                                        ),\n",
    "                batch_size = cfg['TRAIN']['batchsize'], \n",
    "                shuffle    = True\n",
    "                )\n",
    "                    \n",
    "testloader = DataLoader(\n",
    "                dataset = CustomDataset(\n",
    "                                        root          = cfg['DATA']['datadir'],\n",
    "                                        img_size      = cfg['DATA']['imgsize'],\n",
    "                                        transform     = transforms.Compose([transforms.ToTensor()]),\n",
    "                                        img_cls       = cfg['DATA']['imgcls'],\n",
    "                                        mode          = cfg['DATA']['mode'],\n",
    "                                        train         = False\n",
    "                                        ),\n",
    "                #batch_size = cfg['TRAIN']['batchsize'], \n",
    "                batch_size = 1,\n",
    "                shuffle    = False\n",
    "                )\n",
    "bn = torch.load('./save_models/best_bn.pt').to(device)\n",
    "decoder = torch.load('./save_models/best_decoder.pt').to(device)\n",
    "encoder,_ = resnet34(pretrained=True)\n",
    "encoder = encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_anomaly_map(fs_list, ft_list, out_size=224, amap_mode='mul'):\n",
    "    if amap_mode == 'mul':\n",
    "        anomaly_map = np.ones([out_size, out_size])\n",
    "    else:\n",
    "        anomaly_map = np.zeros([out_size, out_size])\n",
    "    a_map_list = []\n",
    "    for i in range(len(ft_list)):\n",
    "        fs = fs_list[i]\n",
    "        ft = ft_list[i]\n",
    "        #fs_norm = F.normalize(fs, p=2)\n",
    "        #ft_norm = F.normalize(ft, p=2)\n",
    "        a_map = 1 - F.cosine_similarity(fs, ft) #loss 계산 \n",
    "        a_map = torch.unsqueeze(a_map, dim=1)\n",
    "        a_map = F.interpolate(a_map, size=out_size, mode='bilinear', align_corners=True)\n",
    "        a_map = a_map[0, 0, :, :].to('cpu').detach().numpy()\n",
    "        a_map_list.append(a_map)\n",
    "        if amap_mode == 'mul':\n",
    "            anomaly_map *= a_map\n",
    "        else:\n",
    "            anomaly_map += a_map\n",
    "    return anomaly_map, a_map_list\n",
    "\n",
    "def show_cam_on_image(img, anomaly_map):\n",
    "    #if anomaly_map.shape != img.shape:\n",
    "    #    anomaly_map = cv2.applyColorMap(np.uint8(anomaly_map), cv2.COLORMAP_JET)\n",
    "    cam = np.float32(anomaly_map)/255 + np.float32(img)/255\n",
    "    cam = cam / np.max(cam)\n",
    "    return np.uint8(255 * cam)\n",
    "\n",
    "def min_max_norm(image):\n",
    "    a_min, a_max = image.min(), image.max()\n",
    "    return (image-a_min)/(a_max - a_min)\n",
    "\n",
    "def cvt2heatmap(gray):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(gray), cv2.COLORMAP_JET)\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "from test import compute_pro\n",
    "from sklearn.metrics import roc_auc_score,auc \n",
    "bn.eval()\n",
    "decoder.eval()\n",
    "encoder.eval()\n",
    "\n",
    "gt_list_px = []\n",
    "pr_list_px = []\n",
    "gt_list_sp = []\n",
    "pr_list_sp = []\n",
    "aupro_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img,gt,label in testloader:\n",
    "        \n",
    "        img = img.to(device)\n",
    "        inputs = encoder(img)\n",
    "        outputs = decoder(bn(inputs))\n",
    "        anomaly_map,_ = cal_anomaly_map(inputs,outputs,img.shape[-1],amap_mode='a')\n",
    "        anomaly_map = gaussian_filter(anomaly_map, sigma=4)\n",
    "        gt[gt > 0.5] = 1\n",
    "        gt[gt <= 0.5] = 0\n",
    "        if label.item()!=0:\n",
    "            aupro_list.append(compute_pro(gt.squeeze(0).cpu().numpy().astype(int),\n",
    "                                            anomaly_map[np.newaxis,:,:]))\n",
    "        gt_list_px.extend(gt.cpu().numpy().astype(int).ravel())\n",
    "        pr_list_px.extend(anomaly_map.ravel())\n",
    "        gt_list_sp.append(np.max(gt.cpu().numpy().astype(int)))\n",
    "        pr_list_sp.append(np.max(anomaly_map))\n",
    "        \n",
    "    auroc_px = round(roc_auc_score(gt_list_px, pr_list_px), 3)\n",
    "    auroc_sp = round(roc_auc_score(gt_list_sp, pr_list_sp), 3)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (256,256) (256,256,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39m255\u001b[39m, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m     27\u001b[0m img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39muint8(min_max_norm(img)\u001b[39m*\u001b[39m\u001b[39m255\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m ano_map \u001b[39m=\u001b[39m show_cam_on_image(img, ano_map)\n\u001b[1;32m     29\u001b[0m plt\u001b[39m.\u001b[39mimshow(ano_map)\n\u001b[1;32m     30\u001b[0m plt\u001b[39m.\u001b[39maxis(\u001b[39m'\u001b[39m\u001b[39moff\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m, in \u001b[0;36mshow_cam_on_image\u001b[0;34m(img, anomaly_map)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow_cam_on_image\u001b[39m(img, anomaly_map):\n\u001b[1;32m     24\u001b[0m     \u001b[39m#if anomaly_map.shape != img.shape:\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[39m#    anomaly_map = cv2.applyColorMap(np.uint8(anomaly_map), cv2.COLORMAP_JET)\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     cam \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mfloat32(anomaly_map)\u001b[39m/\u001b[39;49m\u001b[39m255\u001b[39;49m \u001b[39m+\u001b[39;49m np\u001b[39m.\u001b[39;49mfloat32(img)\u001b[39m/\u001b[39;49m\u001b[39m255\u001b[39;49m\n\u001b[1;32m     27\u001b[0m     cam \u001b[39m=\u001b[39m cam \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39mmax(cam)\n\u001b[1;32m     28\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39muint8(\u001b[39m255\u001b[39m \u001b[39m*\u001b[39m cam)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (256,256) (256,256,3) "
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "from test import compute_pro\n",
    "from sklearn.metrics import roc_auc_score,auc \n",
    "import cv2 \n",
    "bn.eval()\n",
    "decoder.eval()\n",
    "encoder.eval()\n",
    "\n",
    "gt_list_px = []\n",
    "pr_list_px = []\n",
    "gt_list_sp = []\n",
    "pr_list_sp = []\n",
    "aupro_list = []\n",
    "\n",
    "n = 0 \n",
    "with torch.no_grad():\n",
    "    for img,gt,label in testloader:\n",
    "        \n",
    "        img = img.to(device)\n",
    "        inputs = encoder(img)\n",
    "        outputs = decoder(bn(inputs))\n",
    "        anomaly_map,amap_list = cal_anomaly_map(inputs,outputs,img.shape[-1],amap_mode='a')\n",
    "        anomaly_map = gaussian_filter(anomaly_map, sigma=4)\n",
    "        ano_map = min_max_norm(anomaly_map)\n",
    "        ano_map = cvt2heatmap(ano_map*255)\n",
    "        img = cv2.cvtColor(img.permute(0, 2, 3, 1).cpu().numpy()[0] * 255, cv2.COLOR_BGR2RGB)\n",
    "        img = np.uint8(min_max_norm(img)*255)\n",
    "        ano_map = show_cam_on_image(img, ano_map)\n",
    "        plt.imshow(ano_map)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        n +=1 \n",
    "        \n",
    "        if n == 10:\n",
    "            break \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
